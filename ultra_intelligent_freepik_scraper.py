#!/usr/bin/env python3
"""
Ultra Intelligent Freepik Scraper
Advanced game-focused asset extraction from Freepik
"""

import time
import json
import random
from typing import Dict, List, Optional
from bs4 import BeautifulSoup
import requests
from safe_scraping import SafeScrapingManager
from urllib.parse import urljoin, urlparse

class UltraIntelligentFreepikScraper:
    """Ultra intelligent Freepik scraper for game assets"""
    
    def __init__(self):
        self.base_url = "https://www.freepik.com"
        self.site_name = "Freepik"
        self.safe_scraper = SafeScrapingManager()
        self.scraped_assets = []
        self.site_intelligence = {}
        
        print("üß† Ultra Intelligent Freepik Scraper Initialized")
        print("=" * 60)
        print("üéØ Features:")
        print("   ‚úÖ Game-focused asset search")
        print("   ‚úÖ Vector and raster image support")
        print("   ‚úÖ Quality scoring system")
        print("   ‚úÖ License information parsing")
        print("   ‚úÖ Multi-category extraction")
        print("   ‚úÖ Advanced filtering")
    
    def analyze_and_scrape(self, limit: int = None) -> List[Dict]:
        """Main ultra intelligent scraping method"""
        print("üß† Starting Ultra Intelligent Freepik Scraping...")
        print("=" * 60)
        
        # Phase 1: Site Intelligence Analysis
        print("üîç Phase 1: Site Intelligence Analysis")
        self.site_intelligence = self._perform_site_analysis()
        
        # Phase 2: Game-Focused Strategy
        print("üéØ Phase 2: Game-Focused Scraping Strategy")
        strategy = self._determine_scraping_strategy()
        
        # Phase 3: Multi-Search Asset Extraction
        print("üì¶ Phase 3: Multi-Search Asset Extraction")
        assets = self._execute_intelligent_scraping(strategy, limit)
        
        # Phase 4: Quality Enhancement & Scoring
        print("‚ú® Phase 4: Quality Enhancement & Scoring")
        enhanced_assets = self._enhance_and_score_assets(assets)
        
        # Phase 5: Results Optimization
        print("üéØ Phase 5: Results Optimization")
        optimized_assets = self._optimize_results(enhanced_assets)
        
        return optimized_assets
    
    def _perform_site_analysis(self) -> Dict:
        """Perform intelligent site analysis"""
        print("üåê Analyzing Freepik structure...")
        
        # Test search functionality
        test_search = "game ui"
        search_url = f"{self.base_url}/search?format=search&query={test_search.replace(' ', '%20')}"
        
        try:
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
            }
            response = requests.get(search_url, headers=headers, timeout=15)
        except Exception as e:
            print(f"   ‚ùå Site analysis failed: {e}")
            return {'error': 'Cannot access site'}
        
        if not response or response.status_code != 200:
            return {'error': f'Site returned {response.status_code if response else "no response"}'}
        
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # Analyze image containers
        image_structure = self._analyze_image_structure(soup)
        
        # Test search categories
        search_categories = self._get_game_search_categories()
        
        intelligence = {
            'image_structure': image_structure,
            'search_categories': search_categories,
            'base_url': self.base_url,
            'analysis_time': time.time()
        }
        
        print(f"   üîç Image structure analyzed")
        print(f"   üìÇ Search categories prepared")
        
        return intelligence
    
    def _analyze_image_structure(self, soup: BeautifulSoup) -> Dict:
        """Analyze image container structure"""
        selectors = [
            'figure[data-id]',
            '.showcase__item',
            '.grid-item',
            '[data-track="resource"]',
            '.resource'
        ]
        
        best_selector = None
        max_images = 0
        
        for selector in selectors:
            images = soup.select(selector)
            if len(images) > max_images:
                max_images = len(images)
                best_selector = selector
                print(f"   üéØ Testing selector '{selector}': {len(images)} images found")
        
        return {
            'best_selector': best_selector or 'figure[data-id]',
            'image_count_sample': max_images,
            'structure_analyzed': True
        }
    
    def _get_game_search_categories(self) -> List[Dict]:
        """Get game-focused search categories"""
        return [
            {
                'name': 'game_ui',
                'terms': ['game ui', 'game interface', 'game button', 'game menu'],
                'priority': 1
            },
            {
                'name': 'game_icons',
                'terms': ['game icon', 'game symbol', 'gaming icon', 'game element'],
                'priority': 1
            },
            {
                'name': 'game_backgrounds',
                'terms': ['game background', 'gaming background', 'game scene', 'game environment'],
                'priority': 2
            },
            {
                'name': 'game_characters',
                'terms': ['game character', 'gaming character', 'pixel character', 'game avatar'],
                'priority': 2
            },
            {
                'name': 'game_objects',
                'terms': ['game object', 'game item', 'game weapon', 'game treasure'],
                'priority': 3
            },
            {
                'name': 'game_effects',
                'terms': ['game effect', 'game explosion', 'game particle', 'game magic'],
                'priority': 3
            }
        ]
    
    def _determine_scraping_strategy(self) -> Dict:
        """Determine optimal scraping strategy"""
        strategy = {
            'primary_method': 'multi_search',
            'image_selector': 'figure[data-id]',
            'search_categories': [],
            'images_per_search': 12,
            'max_pages_per_search': 2,
            'rate_limiting': 2.0,
            'quality_filters': ['game_relevant', 'free_license']
        }
        
        # Use discovered image structure
        if self.site_intelligence.get('image_structure', {}).get('best_selector'):
            strategy['image_selector'] = self.site_intelligence['image_structure']['best_selector']
        
        # Use search categories
        if self.site_intelligence.get('search_categories'):
            strategy['search_categories'] = self.site_intelligence['search_categories']
        
        print(f"   üéØ Strategy: {strategy['primary_method']}")
        print(f"   üìÇ Search categories: {len(strategy['search_categories'])}")
        print(f"   üîç Image selector: {strategy['image_selector']}")
        
        return strategy
    
    def _execute_intelligent_scraping(self, strategy: Dict, limit: int = None) -> List[Dict]:
        """Execute intelligent scraping"""
        assets = []
        limit = limit or 50
        
        print(f"üéØ Target: {limit} images")
        
        search_categories = strategy['search_categories']
        images_per_category = limit // len(search_categories) if search_categories else limit
        
        for category in search_categories:
            if len(assets) >= limit:
                break
            
            try:
                category_assets = self._scrape_search_category(category, strategy, images_per_category)
                assets.extend(category_assets)
                
                print(f"   üìÇ {category['name']}: {len(category_assets)} images")
                time.sleep(strategy['rate_limiting'])
                
            except Exception as e:
                print(f"‚ö†Ô∏è Error scraping category {category['name']}: {e}")
                continue
        
        return assets[:limit]
    
    def _scrape_search_category(self, category: Dict, strategy: Dict, limit: int) -> List[Dict]:
        """Scrape images from a search category"""
        assets = []
        
        for search_term in category['terms']:
            if len(assets) >= limit:
                break
            
            try:
                search_assets = self._scrape_search_term(search_term, strategy, limit - len(assets))
                
                # Add category info
                for asset in search_assets:
                    asset['search_category'] = category['name']
                    asset['search_term'] = search_term
                    asset['category_priority'] = category['priority']
                
                assets.extend(search_assets)
                
            except Exception as e:
                print(f"‚ö†Ô∏è Error scraping term '{search_term}': {e}")
                continue
        
        return assets
    
    def _scrape_search_term(self, search_term: str, strategy: Dict, limit: int) -> List[Dict]:
        """Scrape images for a specific search term"""
        assets = []
        
        for page in range(1, strategy['max_pages_per_search'] + 1):
            if len(assets) >= limit:
                break
            
            # Build search URL
            search_url = f"{self.base_url}/search?format=search&query={search_term.replace(' ', '%20')}&page={page}"
            
            try:
                headers = {
                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
                }
                response = requests.get(search_url, headers=headers, timeout=15)
            except Exception as e:
                print(f"   ‚ùå Request failed for '{search_term}' page {page}: {e}")
                continue
            
            if not response or response.status_code != 200:
                continue
            
            soup = BeautifulSoup(response.content, 'html.parser')
            page_assets = self._extract_images_from_page(soup, strategy)
            
            if not page_assets:
                break  # No more images
            
            assets.extend(page_assets)
            time.sleep(1)  # Page rate limiting
        
        return assets[:limit]
    
    def _extract_images_from_page(self, soup: BeautifulSoup, strategy: Dict) -> List[Dict]:
        """Extract images from a page"""
        images = []
        
        image_elements = soup.select(strategy['image_selector'])
        
        for elem in image_elements:
            try:
                image_data = self._extract_image_data(elem)
                if image_data and self._passes_quality_filters(image_data, strategy):
                    images.append(image_data)
            except Exception as e:
                continue
        
        return images
    
    def _extract_image_data(self, element) -> Optional[Dict]:
        """Extract image data from element"""
        try:
            # Extract image link
            link_elem = element.select_one('a')
            if not link_elem:
                return None
            
            image_url = urljoin(self.base_url, link_elem.get('href'))
            
            # Extract image source
            img_elem = element.select_one('img')
            if not img_elem:
                return None
            
            preview_image = img_elem.get('src') or img_elem.get('data-src')
            if preview_image and not preview_image.startswith('http'):
                preview_image = urljoin(self.base_url, preview_image)
            
            # Extract title/alt text
            title = (
                img_elem.get('alt') or
                link_elem.get('title') or
                element.get('data-title') or
                'Freepik Asset'
            )
            
            # Extract author if available
            author_elem = element.select_one('.author, .user-name, [data-author]')
            author = author_elem.get_text(strip=True) if author_elem else ""
            
            # Extract tags from title and context
            tags = self._extract_tags_from_title(title)
            
            return {
                'title': title,
                'source_url': image_url,
                'preview_image': preview_image,
                'author': author,
                'tags': tags,
                'site': 'Freepik',
                'license': 'Freepik License',
                'asset_type': 'Vector/Image',
                'timestamp': time.time()
            }
            
        except Exception as e:
            return None

    def _extract_tags_from_title(self, title: str) -> List[str]:
        """Extract relevant tags from title"""
        tags = []
        title_lower = title.lower()

        # Game-related keywords
        game_keywords = [
            'game', 'gaming', 'ui', 'interface', 'button', 'icon', 'menu',
            'character', 'avatar', 'weapon', 'magic', 'fantasy', 'pixel',
            'retro', 'arcade', 'rpg', 'adventure', 'action', 'strategy'
        ]

        for keyword in game_keywords:
            if keyword in title_lower:
                tags.append(keyword)

        return tags[:8]  # Limit to 8 tags

    def _passes_quality_filters(self, image_data: Dict, strategy: Dict) -> bool:
        """Check if image passes quality filters"""
        filters = strategy.get('quality_filters', [])

        for filter_type in filters:
            if filter_type == 'game_relevant':
                # Check if image is game-relevant
                title = image_data.get('title', '').lower()
                tags = ' '.join(image_data.get('tags', [])).lower()

                game_keywords = ['game', 'gaming', 'ui', 'interface', 'character', 'icon']

                if not any(keyword in title or keyword in tags for keyword in game_keywords):
                    return False

            elif filter_type == 'free_license':
                # Check for free license indicators
                title = image_data.get('title', '').lower()
                if 'premium' in title or 'pro' in title:
                    return False

        return True

    def _enhance_and_score_assets(self, assets: List[Dict]) -> List[Dict]:
        """Enhance assets with quality scoring"""
        enhanced_assets = []

        print(f"‚ú® Enhancing {len(assets)} images...")

        for asset in assets:
            try:
                enhanced = asset.copy()

                # Calculate quality score
                enhanced['quality_score'] = self._calculate_quality_score(asset)

                # Enhance metadata
                enhanced = self._enhance_image_metadata(enhanced)

                enhanced_assets.append(enhanced)

            except Exception as e:
                enhanced_assets.append(asset)
                continue

        return enhanced_assets

    def _calculate_quality_score(self, asset: Dict) -> float:
        """Calculate image quality score"""
        score = 0.0

        # Title quality (25%)
        title = asset.get('title', '')
        if title and len(title) > 5 and title != 'Freepik Asset':
            score += 0.25

        # Preview image availability (25%)
        if asset.get('preview_image'):
            score += 0.25

        # Tags availability (20%)
        tags = asset.get('tags', [])
        if tags:
            score += 0.2

        # Author information (10%)
        if asset.get('author'):
            score += 0.1

        # Search relevance (20%)
        search_category = asset.get('search_category', '')
        category_priority = asset.get('category_priority', 3)
        if search_category:
            priority_score = (4 - category_priority) / 3 * 0.2  # Higher priority = higher score
            score += priority_score

        return min(score, 1.0)

    def _enhance_image_metadata(self, asset: Dict) -> Dict:
        """Enhance image with additional metadata"""
        # Categorize based on search category and tags
        search_category = asset.get('search_category', '')
        tags = asset.get('tags', [])
        title = asset.get('title', '').lower()

        # Determine asset category
        if search_category == 'game_ui':
            asset['category'] = 'UI Element'
        elif search_category == 'game_icons':
            asset['category'] = 'Icon'
        elif search_category == 'game_backgrounds':
            asset['category'] = 'Background'
        elif search_category == 'game_characters':
            asset['category'] = 'Character'
        elif search_category == 'game_objects':
            asset['category'] = 'Object'
        elif search_category == 'game_effects':
            asset['category'] = 'Effect'
        else:
            asset['category'] = 'Game Asset'

        # Add usage suggestions
        usage_suggestions = []

        if 'ui' in title or search_category == 'game_ui':
            usage_suggestions.extend(['User Interface', 'HUD', 'Menu Design'])
        elif 'icon' in title or search_category == 'game_icons':
            usage_suggestions.extend(['Game Icons', 'UI Elements', 'Inventory'])
        elif 'background' in title or search_category == 'game_backgrounds':
            usage_suggestions.extend(['Game Background', 'Level Design', 'Environment'])
        else:
            usage_suggestions.extend(['Game Development', 'Asset Design', 'Graphics'])

        asset['usage_suggestions'] = usage_suggestions

        # Add technical specifications
        asset['technical_specs'] = {
            'format': 'Vector/Raster',
            'license': 'Freepik License (Attribution required)',
            'commercial_use': True,
            'modifications_allowed': True
        }

        return asset

    def _optimize_results(self, assets: List[Dict]) -> List[Dict]:
        """Optimize and filter results"""
        print(f"üéØ Optimizing {len(assets)} images...")

        # Remove duplicates
        seen_titles = set()
        seen_urls = set()
        unique_assets = []

        for asset in assets:
            title = asset.get('title', '').lower()
            url = asset.get('source_url', '')

            if title not in seen_titles and url not in seen_urls:
                seen_titles.add(title)
                if url:
                    seen_urls.add(url)
                unique_assets.append(asset)

        # Sort by quality score and category priority
        unique_assets.sort(key=lambda x: (x.get('quality_score', 0), -x.get('category_priority', 3)), reverse=True)

        # Group by category
        category_stats = {}
        for asset in unique_assets:
            category = asset.get('category', 'Unknown')
            category_stats[category] = category_stats.get(category, 0) + 1

        print(f"‚úÖ Optimization complete: {len(unique_assets)} unique images")
        if unique_assets:
            avg_quality = sum(a.get('quality_score', 0) for a in unique_assets) / len(unique_assets)
            print(f"üìä Average quality score: {avg_quality:.2f}")
            print(f"üìÇ Categories: {len(category_stats)}")

        return unique_assets

# Test function
def test_ultra_intelligent_freepik_scraper():
    """Test the ultra intelligent Freepik scraper"""
    print("üß™ Testing Ultra Intelligent Freepik Scraper")
    print("=" * 60)

    scraper = UltraIntelligentFreepikScraper()

    try:
        assets = scraper.analyze_and_scrape(limit=15)

        print(f"\nüìä SCRAPING RESULTS")
        print(f"   üéØ Total images: {len(assets)}")

        if assets:
            avg_quality = sum(a.get('quality_score', 0) for a in assets) / len(assets)
            print(f"   üìà Average quality score: {avg_quality:.2f}")

            # Count by category
            categories = {}
            for asset in assets:
                category = asset.get('category', 'Unknown')
                categories[category] = categories.get(category, 0) + 1

            print(f"\nüìÇ Categories:")
            for category, count in categories.items():
                print(f"   {category}: {count} images")

            print(f"\nüé® Sample Images:")
            for i, asset in enumerate(assets[:5], 1):
                print(f"   {i}. {asset['title'][:50]}...")
                print(f"      Quality: {asset.get('quality_score', 0):.2f}")
                print(f"      Category: {asset.get('category', 'Unknown')}")
                print(f"      Search: {asset.get('search_category', 'Unknown')}")

        return assets

    except Exception as e:
        print(f"‚ùå Test failed: {e}")
        return []

if __name__ == "__main__":
    test_ultra_intelligent_freepik_scraper()
